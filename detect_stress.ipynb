{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on [This](https://www.kaggle.com/code/vijay20213/stress-identification-nlp-with-best-prediction) Kaggle Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Look & Keep Only Text, Target Label Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2838 entries, 0 to 2837\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   subreddit         2838 non-null   object \n",
      " 1   post_id           2838 non-null   object \n",
      " 2   sentence_range    2838 non-null   object \n",
      " 3   text              2838 non-null   object \n",
      " 4   label             2838 non-null   int64  \n",
      " 5   confidence        2838 non-null   float64\n",
      " 6   social_timestamp  2838 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 155.3+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_df = pd.read_csv('data/Stress.csv')\n",
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_id</th>\n",
       "      <th>sentence_range</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>social_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>8601tu</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1521614353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assistance</td>\n",
       "      <td>8lbrx9</td>\n",
       "      <td>(0, 5)</td>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1527009817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit post_id sentence_range  \\\n",
       "0        ptsd  8601tu       (15, 20)   \n",
       "1  assistance  8lbrx9         (0, 5)   \n",
       "\n",
       "                                                text  label  confidence  \\\n",
       "0  He said he had not felt that way before, sugge...      1         0.8   \n",
       "1  Hey there r/assistance, Not sure if this is th...      0         1.0   \n",
       "\n",
       "   social_timestamp  \n",
       "0        1521614353  \n",
       "1        1527009817  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_id</th>\n",
       "      <th>sentence_range</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>social_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>relationships</td>\n",
       "      <td>7sdyx6</td>\n",
       "      <td>[100, 105]</td>\n",
       "      <td>Back to my dad, during lunch he wanted to say ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1516709505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>relationships</td>\n",
       "      <td>7o78rj</td>\n",
       "      <td>(0, 5)</td>\n",
       "      <td>I’m a Canadian traveling in India and staying ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1515111891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>9vaxit</td>\n",
       "      <td>[0, 5]</td>\n",
       "      <td>November 8 is the anniversary of when I was ki...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1541690897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>homeless</td>\n",
       "      <td>7r7wqs</td>\n",
       "      <td>(11, 16)</td>\n",
       "      <td>I got as far as Illinois when he ghosted me af...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1516258116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>relationships</td>\n",
       "      <td>7pg3a7</td>\n",
       "      <td>(55, 60)</td>\n",
       "      <td>She didn’t have room for it where she was curr...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1515596406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit post_id sentence_range  \\\n",
       "1601  relationships  7sdyx6     [100, 105]   \n",
       "2447  relationships  7o78rj         (0, 5)   \n",
       "1471           ptsd  9vaxit         [0, 5]   \n",
       "2589       homeless  7r7wqs       (11, 16)   \n",
       "1956  relationships  7pg3a7       (55, 60)   \n",
       "\n",
       "                                                   text  label  confidence  \\\n",
       "1601  Back to my dad, during lunch he wanted to say ...      0    0.571429   \n",
       "2447  I’m a Canadian traveling in India and staying ...      0    1.000000   \n",
       "1471  November 8 is the anniversary of when I was ki...      1    0.800000   \n",
       "2589  I got as far as Illinois when he ghosted me af...      1    0.666667   \n",
       "1956  She didn’t have room for it where she was curr...      0    1.000000   \n",
       "\n",
       "      social_timestamp  \n",
       "1601        1516709505  \n",
       "2447        1515111891  \n",
       "1471        1541690897  \n",
       "2589        1516258116  \n",
       "1956        1515596406  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Back to my dad, during lunch he wanted to say some words to my GF, to encourage her to keep studying the doctorate, he said that if she felt that money was an issue, that don't let her that take her down, that doctorates in our country earn very poorly but that getting that degree would open doors to work abroad and land a job she would love. You see, my dad didn't know (well, I've told him plenty of times, but I figured he forgot at the time) that my GF's mom was a doctorate. My GF's mom openly told in front of my that she didn't earn enough for the years of study and work she did, everybody in our country knows that doctorates don't earn enough money for the effort, capacity and dedication they're required to do/have. But when my dad said those words, nobody said anything. I didn't take it as offensive.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.loc[1601, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2838 entries, 0 to 2837\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    2838 non-null   object\n",
      " 1   label   2838 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 44.5+ KB\n"
     ]
    }
   ],
   "source": [
    "ignored_cols = ['subreddit','post_id','sentence_range','confidence','social_timestamp']\n",
    "df = raw_df.drop(columns=ignored_cols)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatively balanced starting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    1488\n",
       "0    1350\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages Needed\n",
    "\n",
    "from spacy import load --> errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/yichenzhang/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/yichenzhang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet2022 to\n",
      "[nltk_data]     /home/yichenzhang/nltk_data...\n",
      "[nltk_data]   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/yichenzhang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/yichenzhang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4') # Open Multilingual Wordnet, this is an lexical database \n",
    "nltk.download('wordnet') \n",
    "nltk.download('wordnet2022')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pare Down Words - Token Level: Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = list(stopwords.words('english'))\n",
    "'dont' in stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of misspellings that leave out apostrophes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "205\n"
     ]
    }
   ],
   "source": [
    "print(len(stop_words))\n",
    "for stopword in stop_words:\n",
    "    if \"'\" in stopword:\n",
    "        stop_words.append(re.sub(\"'\", \"\", stopword))\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stop_words)\n",
    "type(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(sent, stopwords=stop_words):\n",
    "    \"\"\"Use RegEx to clean raw text data\"\"\"\n",
    "    try:\n",
    "        # brackets replacing by space\n",
    "        sent = re.sub('[][)(]',' ',sent)\n",
    "\n",
    "        # url removing\n",
    "        sent = [word for word in sent.split() if not urlparse(word).scheme]\n",
    "        sent = ' '.join(sent)\n",
    "\n",
    "        # removing escap characters\n",
    "        sent = re.sub(r\"\\@\\w+\", \"\", sent)\n",
    "\n",
    "        # removing html tags \n",
    "        sent = re.sub(re.compile(\"<.*?>\"),'',sent)\n",
    "\n",
    "        # getting only characters and numbers from text\n",
    "        sent = re.sub(\"[^A-Za-z0-9]\",' ',sent)\n",
    "\n",
    "        # lower case all words\n",
    "        sent = sent.lower()\n",
    "        \n",
    "        # Remove extra whitespace between words\n",
    "        sent = [word.strip() for word in sent.split()]\n",
    "        sent = ' '.join(sent)\n",
    "\n",
    "        # word tokenization\n",
    "        tokens = word_tokenize(sent)\n",
    "        \n",
    "        # removing words which are in stopwords\n",
    "        tokens = [t for t in tokens if t not in stopwords]\n",
    "        \n",
    "        # lemmatization\n",
    "        sent = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "        sent = ' '.join(sent)\n",
    "        return sent\n",
    "    \n",
    "    except Exception as ex:\n",
    "        print(sent,\"\\n\")\n",
    "        print(\"Error \",ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Dr. Fred Penzel's Articles &lt;url&gt; A leading exp...</td>\n",
       "      <td>0</td>\n",
       "      <td>dr fred penzel article leading expert ocd dr p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>&amp;#x200B; Hey everyone, Being that Hurricane Fl...</td>\n",
       "      <td>1</td>\n",
       "      <td>x200b hey everyone hurricane florence occurred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>We are, by far, the youngest people around mar...</td>\n",
       "      <td>0</td>\n",
       "      <td>far youngest people around marina named beauti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "131   Dr. Fred Penzel's Articles <url> A leading exp...      0   \n",
       "654   &#x200B; Hey everyone, Being that Hurricane Fl...      1   \n",
       "1178  We are, by far, the youngest people around mar...      0   \n",
       "\n",
       "                                         processed_text  \n",
       "131   dr fred penzel article leading expert ocd dr p...  \n",
       "654   x200b hey everyone hurricane florence occurred...  \n",
       "1178  far youngest people around marina named beauti...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_text'] = df['text'].apply(lambda text: process_text(text))\n",
    "df.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'than' in stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'successfully'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dr. Fred Penzel\\'s Articles <url> A leading expert on OCD, Dr. Penzel has a collection of great articles online based on years of successfully treating patients with OCD. Particularly good for highlighting how the \"less-obvious\" variants of OCD can be treated. Check out Article 12 \"Ten Things You Need to Know to Overcome OCD\" for starters. Top Tips: Carry out [Exposure and Response Prevention].'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_idx = 131\n",
    "df.loc[sample_idx, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dr fred penzel article leading expert ocd dr penzel collection great article online based year successfully treating patient ocd particularly good highlighting le obvious variant ocd treated check article 12 ten thing need know overcome ocd starter top carry exposure response prevention'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[sample_idx, 'processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint \n",
    "\n",
    "rand_index = randint(0, len(df)-1)\n",
    "rand_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEEMINGLY RESOLVED: Not all the stopwords are being removed - possibility to improve here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without process --->  My ex thought that show was terrific inspiration. He used it to discuss “what if”s with his guy friends, who I hope had no idea how real he is about that shit. I called it “The Rape Along/Beat Along Show” for the longest time. I still do when Gramma isn’t listening. Last time I unexpectedly came across the DVD set (Grampy accidentally left it at my place on the kitchen table, and, yes, he’d been told not to leave it where I might see it)...\n",
      "\n",
      "after process --->  ex thought show terrific inspiration used discus guy friend hope idea real shit called rape along beat along show longest time still gramma listening last time unexpectedly came across dvd set grampy accidentally left place kitchen table yes told leave might see\n"
     ]
    }
   ],
   "source": [
    "print(\"without process ---> \",df['text'].iloc[rand_index],end='\\n\\n')\n",
    "print(\"after process ---> \",df['processed_text'].iloc[rand_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize (Word Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the reference notebook seems to have removed no words. We may not want to remove rare words, as they may be the most helpful in differentiating different texts, but we may not want to keep all the words, either, as they take up more resources.\n",
    "\n",
    "| MIN_DF | Vocab Size |\n",
    "| --- | --- |\n",
    "| 0.01 | 666 |\n",
    "| 0.001 | 3957 |\n",
    "| 0.0001 | 10,126 |\n",
    "| 0 | 10,126 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DF = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words (Count) Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=MIN_DF)\n",
    "cv_df = cv.fit_transform(df['processed_text'])\n",
    "cv_df.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10pm</th>\n",
       "      <th>10th</th>\n",
       "      <th>11</th>\n",
       "      <th>11th</th>\n",
       "      <th>12</th>\n",
       "      <th>120</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoloft</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3957 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  10  100  1000  10pm  10th  11  11th  12  120  ...  york  young  \\\n",
       "0    0   0    0     0     0     0   0     0   0    0  ...     0      0   \n",
       "1    0   0    0     0     0     0   0     0   0    0  ...     0      0   \n",
       "2    0   0    0     0     0     0   0     0   0    0  ...     0      0   \n",
       "\n",
       "   younger  youngest  youth  youtube  yr  zero  zoloft  zone  \n",
       "0        0         0      0        0   0     0       0     0  \n",
       "1        0         0      0        0   0     0       0     0  \n",
       "2        0         0      0        0   0     0       0     0  \n",
       "\n",
       "[3 rows x 3957 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df = pd.DataFrame(cv_df.toarray(),columns=cv.get_feature_names_out())\n",
    "cv_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term Frequency, Inverse Document Frequency Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.07822263, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = TfidfVectorizer(min_df=MIN_DF)\n",
    "tf_df = tf.fit_transform(df['processed_text'])\n",
    "tf_df.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10pm</th>\n",
       "      <th>10th</th>\n",
       "      <th>11</th>\n",
       "      <th>11th</th>\n",
       "      <th>12</th>\n",
       "      <th>120</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoloft</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3957 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000   10  100  1000  10pm  10th   11  11th   12  120  ...  york  young  \\\n",
       "0  0.0  0.0  0.0   0.0   0.0   0.0  0.0   0.0  0.0  0.0  ...   0.0    0.0   \n",
       "1  0.0  0.0  0.0   0.0   0.0   0.0  0.0   0.0  0.0  0.0  ...   0.0    0.0   \n",
       "2  0.0  0.0  0.0   0.0   0.0   0.0  0.0   0.0  0.0  0.0  ...   0.0    0.0   \n",
       "\n",
       "   younger  youngest  youth  youtube   yr  zero  zoloft  zone  \n",
       "0      0.0       0.0    0.0      0.0  0.0   0.0     0.0   0.0  \n",
       "1      0.0       0.0    0.0      0.0  0.0   0.0     0.0   0.0  \n",
       "2      0.0       0.0    0.0      0.0  0.0   0.0     0.0   0.0  \n",
       "\n",
       "[3 rows x 3957 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df = pd.DataFrame(tf_df.toarray(),columns=tf.get_feature_names_out())\n",
    "tf_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10pm</th>\n",
       "      <th>10th</th>\n",
       "      <th>11</th>\n",
       "      <th>11th</th>\n",
       "      <th>12</th>\n",
       "      <th>120</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoloft</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012414</td>\n",
       "      <td>0.024240</td>\n",
       "      <td>0.019533</td>\n",
       "      <td>0.012899</td>\n",
       "      <td>0.007261</td>\n",
       "      <td>0.007039</td>\n",
       "      <td>0.014251</td>\n",
       "      <td>0.007515</td>\n",
       "      <td>0.018149</td>\n",
       "      <td>0.007704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009003</td>\n",
       "      <td>0.019467</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.009648</td>\n",
       "      <td>0.012501</td>\n",
       "      <td>0.013893</td>\n",
       "      <td>0.012343</td>\n",
       "      <td>0.013497</td>\n",
       "      <td>0.008084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.417446</td>\n",
       "      <td>0.347310</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.349854</td>\n",
       "      <td>0.284812</td>\n",
       "      <td>0.247687</td>\n",
       "      <td>0.274153</td>\n",
       "      <td>0.218368</td>\n",
       "      <td>0.376203</td>\n",
       "      <td>0.220154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383470</td>\n",
       "      <td>0.269158</td>\n",
       "      <td>0.260087</td>\n",
       "      <td>0.272226</td>\n",
       "      <td>0.364786</td>\n",
       "      <td>0.373744</td>\n",
       "      <td>0.276237</td>\n",
       "      <td>0.253284</td>\n",
       "      <td>0.366865</td>\n",
       "      <td>0.322071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 3957 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               000           10          100         1000         10pm  \\\n",
       "count  2838.000000  2838.000000  2838.000000  2838.000000  2838.000000   \n",
       "mean      0.000677     0.003727     0.002011     0.000667     0.000229   \n",
       "std       0.012414     0.024240     0.019533     0.012899     0.007261   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.417446     0.347310     0.323800     0.349854     0.284812   \n",
       "\n",
       "              10th           11         11th           12          120  ...  \\\n",
       "count  2838.000000  2838.000000  2838.000000  2838.000000  2838.000000  ...   \n",
       "mean      0.000227     0.001028     0.000281     0.001725     0.000288  ...   \n",
       "std       0.007039     0.014251     0.007515     0.018149     0.007704  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       0.247687     0.274153     0.218368     0.376203     0.220154  ...   \n",
       "\n",
       "              york        young      younger     youngest        youth  \\\n",
       "count  2838.000000  2838.000000  2838.000000  2838.000000  2838.000000   \n",
       "mean      0.000279     0.002343     0.001621     0.000592     0.000308   \n",
       "std       0.009003     0.019467     0.017246     0.011429     0.009648   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.383470     0.269158     0.260087     0.272226     0.364786   \n",
       "\n",
       "           youtube           yr         zero       zoloft         zone  \n",
       "count  2838.000000  2838.000000  2838.000000  2838.000000  2838.000000  \n",
       "mean      0.000672     0.000891     0.000726     0.000812     0.000288  \n",
       "std       0.012501     0.013893     0.012343     0.013497     0.008084  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       0.373744     0.276237     0.253284     0.366865     0.322071  \n",
       "\n",
       "[8 rows x 3957 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10pm</th>\n",
       "      <th>10th</th>\n",
       "      <th>11</th>\n",
       "      <th>11th</th>\n",
       "      <th>12</th>\n",
       "      <th>120</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoloft</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.003524</td>\n",
       "      <td>0.025370</td>\n",
       "      <td>0.012333</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.009866</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.001409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.059266</td>\n",
       "      <td>0.161694</td>\n",
       "      <td>0.119582</td>\n",
       "      <td>0.070160</td>\n",
       "      <td>0.032501</td>\n",
       "      <td>0.032501</td>\n",
       "      <td>0.074886</td>\n",
       "      <td>0.037523</td>\n",
       "      <td>0.105678</td>\n",
       "      <td>0.037523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032501</td>\n",
       "      <td>0.126388</td>\n",
       "      <td>0.105746</td>\n",
       "      <td>0.053028</td>\n",
       "      <td>0.032501</td>\n",
       "      <td>0.064942</td>\n",
       "      <td>0.064899</td>\n",
       "      <td>0.059266</td>\n",
       "      <td>0.070121</td>\n",
       "      <td>0.037523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 3957 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               000           10          100         1000         10pm  \\\n",
       "count  2838.000000  2838.000000  2838.000000  2838.000000  2838.000000   \n",
       "mean      0.003524     0.025370     0.012333     0.003524     0.001057   \n",
       "std       0.059266     0.161694     0.119582     0.070160     0.032501   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     2.000000     2.000000     2.000000     1.000000   \n",
       "\n",
       "              10th           11         11th           12          120  ...  \\\n",
       "count  2838.000000  2838.000000  2838.000000  2838.000000  2838.000000  ...   \n",
       "mean      0.001057     0.005638     0.001409     0.010571     0.001409  ...   \n",
       "std       0.032501     0.074886     0.037523     0.105678     0.037523  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       1.000000     1.000000     1.000000     2.000000     1.000000  ...   \n",
       "\n",
       "              york        young      younger     youngest        youth  \\\n",
       "count  2838.000000  2838.000000  2838.000000  2838.000000  2838.000000   \n",
       "mean      0.001057     0.015504     0.009866     0.002819     0.001057   \n",
       "std       0.032501     0.126388     0.105746     0.053028     0.032501   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     2.000000     2.000000     1.000000     1.000000   \n",
       "\n",
       "           youtube           yr         zero       zoloft         zone  \n",
       "count  2838.000000  2838.000000  2838.000000  2838.000000  2838.000000  \n",
       "mean      0.003524     0.004228     0.003524     0.004228     0.001409  \n",
       "std       0.064942     0.064899     0.059266     0.070121     0.037523  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       2.000000     1.000000     1.000000     2.000000     1.000000  \n",
       "\n",
       "[8 rows x 3957 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = randint(0, 50)\n",
    "random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2128, 3957), (710,))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default is 3:1 train:test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cv_df, df['label'], random_state=random_seed, stratify=df['label']\n",
    " )\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((710, 3957), (2128,))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9948308270676691, 0.719718309859155)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definitely overfitting\n",
    "model_lr = LogisticRegression().fit(X_train,y_train)\n",
    "model_lr.score(X_train,y_train),model_lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8923872180451128, 0.7352112676056338)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test accuracy better, but still overfitting\n",
    "model_nb = MultinomialNB().fit(X_train,y_train)\n",
    "model_nb.score(X_train,y_train),model_nb.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9985902255639098, 0.6957746478873239)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Surprising non-performant compared to the others\n",
    "model_rf = RandomForestClassifier().fit(X_train,y_train)\n",
    "model_rf.score(X_train,y_train),model_rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2128, 3957), (2128,))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_td, X_test_td, y_train_td, y_test_td = train_test_split(\n",
    "    tf_df, df['label'], random_state=random_seed, stratify=df['label']\n",
    ")\n",
    "X_train_td.shape, y_train_td.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((710, 3957), (710,))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_td.shape, y_test_td.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7253521126760564"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_td = LogisticRegression().fit(X_train_td, y_train_td)\n",
    "lr_td.score(X_test_td, y_test_td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7295774647887324"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_td = MultinomialNB().fit(X_train_td, y_train_td)\n",
    "nb_td.score(X_test_td, y_test_td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6929577464788732"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_td = RandomForestClassifier().fit(X_train_td, y_train_td)\n",
    "rf_td.score(X_test_td, y_test_td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix & Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Embedding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece5831-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
