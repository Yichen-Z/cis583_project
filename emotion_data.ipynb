{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import randint\n",
    "import re\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: [Kaggle Emotions Dataset for NLP](https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15999 entries, 0 to 15998\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   text     15999 non-null  object\n",
      " 1   emotion  15999 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 250.1+ KB\n"
     ]
    }
   ],
   "source": [
    "edf = pd.read_csv('data/emotions/train.txt', sep=';', header=0, names=['text', 'emotion'])\n",
    "edf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Deal with spellings like \"don t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here if we want to use it. Leaving it off for now.\n",
    "def remove_contracted_terms(raw_text: str) -> str:\n",
    "    sep_patterns = [\n",
    "        r\"[\\s][^\\s]+n[\\s]+t[\\s]\",\n",
    "        r\"[\\s][Ii][\\s]+m[\\s]\",\n",
    "        r\"you[\\s]+re[\\s]\",\n",
    "        r\"they[\\s]+re[\\s]\",\n",
    "        r\"she[\\s]+s[\\s]\",\n",
    "        r\"[\\s]he[\\s]+s[\\s]\",\n",
    "        r\"[\\s][^\\s]+[\\s]+d[\\s]\",\n",
    "        r\"[\\s][^\\s]+[\\s]+ve[\\s]\"\n",
    "    ]\n",
    "    combo_pattern = re.compile('|'.join(sep_patterns))\n",
    "    return re.sub(combo_pattern, ' ', raw_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>contractions_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7680</th>\n",
       "      <td>i dont recall just now yet vividly recall look...</td>\n",
       "      <td>love</td>\n",
       "      <td>i dont recall just now yet vividly recall look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>i feel so embarrassed of myself for even havin...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i feel so embarrassed of myself for even havin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4466</th>\n",
       "      <td>i would feel so excited waiting for the mailma...</td>\n",
       "      <td>joy</td>\n",
       "      <td>i would feel so excited waiting for the mailma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14576</th>\n",
       "      <td>i growled at her i began to feel extremely ann...</td>\n",
       "      <td>anger</td>\n",
       "      <td>i growled at her i began to feel extremely ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>i am right now i feel amused the sounds i hear...</td>\n",
       "      <td>joy</td>\n",
       "      <td>i am right now i feel amused the sounds i hear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  emotion  \\\n",
       "7680   i dont recall just now yet vividly recall look...     love   \n",
       "5747   i feel so embarrassed of myself for even havin...  sadness   \n",
       "4466   i would feel so excited waiting for the mailma...      joy   \n",
       "14576  i growled at her i began to feel extremely ann...    anger   \n",
       "4460   i am right now i feel amused the sounds i hear...      joy   \n",
       "\n",
       "                                    contractions_removed  \n",
       "7680   i dont recall just now yet vividly recall look...  \n",
       "5747   i feel so embarrassed of myself for even havin...  \n",
       "4466   i would feel so excited waiting for the mailma...  \n",
       "14576  i growled at her i began to feel extremely ann...  \n",
       "4460   i am right now i feel amused the sounds i hear...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edf['contractions_removed'] = edf['text'].apply(remove_contracted_terms)\n",
    "edf.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>contractions_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>i feel that learning more about animals and th...</td>\n",
       "      <td>joy</td>\n",
       "      <td>i feel that learning more about animals and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9552</th>\n",
       "      <td>i am feeling a bit apprehensive about carrying...</td>\n",
       "      <td>fear</td>\n",
       "      <td>i am feeling a bit apprehensive about carrying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7054</th>\n",
       "      <td>im feeling very bitter against knight in shini...</td>\n",
       "      <td>anger</td>\n",
       "      <td>im feeling very bitter against knight in shini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>i don t always remember to do this but when i ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>i always remember to do this but when feeling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6786</th>\n",
       "      <td>i feel shes friendly and nice</td>\n",
       "      <td>joy</td>\n",
       "      <td>i feel shes friendly and nice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text emotion  \\\n",
       "4198   i feel that learning more about animals and th...     joy   \n",
       "9552   i am feeling a bit apprehensive about carrying...    fear   \n",
       "7054   im feeling very bitter against knight in shini...   anger   \n",
       "10405  i don t always remember to do this but when i ...   anger   \n",
       "6786                       i feel shes friendly and nice     joy   \n",
       "\n",
       "                                    contractions_removed  \n",
       "4198   i feel that learning more about animals and th...  \n",
       "9552   i am feeling a bit apprehensive about carrying...  \n",
       "7054   im feeling very bitter against knight in shini...  \n",
       "10405  i always remember to do this but when feeling ...  \n",
       "6786                       i feel shes friendly and nice  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edf.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15999 entries, 0 to 15998\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   text     15999 non-null  object\n",
      " 1   emotion  15999 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 250.1+ KB\n"
     ]
    }
   ],
   "source": [
    "edf.drop(columns=['contractions_removed'], inplace=True)\n",
    "edf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Label: Negative Emotion (\"Stress\") as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "joy         5362\n",
       "sadness     4665\n",
       "anger       2159\n",
       "fear        1937\n",
       "love        1304\n",
       "surprise     572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edf['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just going to roughly group \"sadness\", \"anger\", and \"fear\" into \"stressed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3293</th>\n",
       "      <td>i feel this way is probably because i am dumb ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781</th>\n",
       "      <td>i literally just text tychelle to see if she w...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12567</th>\n",
       "      <td>i saw a gain on the scale this morning which d...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  emotion  label\n",
       "3293   i feel this way is probably because i am dumb ...  sadness      1\n",
       "4781   i literally just text tychelle to see if she w...  sadness      1\n",
       "12567  i saw a gain on the scale this morning which d...  sadness      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_stress = {'sadness', 'anger', 'fear'}\n",
    "edf['label'] = edf['emotion'].apply(lambda emotion: 1 if emotion.strip() in possible_stress else 0)\n",
    "edf.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "205\n"
     ]
    }
   ],
   "source": [
    "print(len(stop_words))\n",
    "utils.add_stopwords_missing_apostrophe(stop_words)\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10071</th>\n",
       "      <td>i just got a whole pile of presents so im feel...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "      <td>got whole pile present im feeling generous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15283</th>\n",
       "      <td>i need to know that it can be fixed and that i...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "      <td>need know fixed going feel gorgeous dress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>i see my favorite person suffer and there is n...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1</td>\n",
       "      <td>see favorite person suffer nothing take pain a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8754</th>\n",
       "      <td>i have to visit them every after school and la...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1</td>\n",
       "      <td>visit every school later go tuition time even ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>i feel optimistic that he ll settle in before ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "      <td>feel optimistic settle long arrived</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  emotion  label  \\\n",
       "10071  i just got a whole pile of presents so im feel...      joy      0   \n",
       "15283  i need to know that it can be fixed and that i...      joy      0   \n",
       "2997   i see my favorite person suffer and there is n...  sadness      1   \n",
       "8754   i have to visit them every after school and la...  sadness      1   \n",
       "1780   i feel optimistic that he ll settle in before ...      joy      0   \n",
       "\n",
       "                                          processed_text  \n",
       "10071         got whole pile present im feeling generous  \n",
       "15283          need know fixed going feel gorgeous dress  \n",
       "2997   see favorite person suffer nothing take pain a...  \n",
       "8754   visit every school later go tuition time even ...  \n",
       "1780                 feel optimistic settle long arrived  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edf['processed_text'] = edf['text'].apply(lambda raw_text: utils.process_text(\n",
    "    text_chunk=raw_text, stopwords=stop_words, lemmatizer_obj=lemmatizer\n",
    "))\n",
    "edf.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize (Word Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with Max and Min Document Frequencies for a Reasonable Vocabulary Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_freq_maxes = [0.9, 0.8, 0.7, 0.6, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max doc freq: 0.9\n",
      "Terms: 13435\n",
      "\n",
      "Max doc freq: 0.8\n",
      "Terms: 13435\n",
      "\n",
      "Max doc freq: 0.7\n",
      "Terms: 13435\n",
      "\n",
      "Max doc freq: 0.6\n",
      "Terms: 13434\n",
      "\n",
      "Max doc freq: 0.5\n",
      "Terms: 13434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ceiling in doc_freq_maxes:\n",
    "    tfidf = TfidfVectorizer(max_df=ceiling)\n",
    "    tf_df = tfidf.fit_transform(edf['processed_text'])\n",
    "    tf_df.toarray()\n",
    "    print(f'Max doc freq: {ceiling}\\nTerms: {tf_df.shape[1]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_freq_mins = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min doc freq: 0.1\n",
      "Terms: 4\n",
      "\n",
      "Min doc freq: 0.01\n",
      "Terms: 101\n",
      "\n",
      "Min doc freq: 0.001\n",
      "Terms: 1363\n",
      "\n",
      "Min doc freq: 0.0001\n",
      "Terms: 6496\n",
      "\n",
      "Min doc freq: 1e-05\n",
      "Terms: 13435\n",
      "\n",
      "Min doc freq: 0.0\n",
      "Terms: 13435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for floor in doc_freq_mins:\n",
    "    tfidf = TfidfVectorizer(min_df=floor)\n",
    "    tf_df = tfidf.fit_transform(edf['processed_text'])\n",
    "    tf_df.toarray()\n",
    "    print(f'Min doc freq: {floor}\\nTerms: {tf_df.shape[1]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try max_df = 0.6 and min_df = 0.0001\n",
    "MAX_DF = 0.6\n",
    "MIN_DF = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15999, 6495)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=MIN_DF, max_df=MAX_DF)\n",
    "tf_df = tfidf.fit_transform(edf['processed_text'])\n",
    "tf_df.toarray()\n",
    "tf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abc</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>abit</th>\n",
       "      <th>...</th>\n",
       "      <th>zach</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zen</th>\n",
       "      <th>zero</th>\n",
       "      <th>zest</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zumba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11948</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9851</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 6495 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        aa  abandon  abandoned  abandoning  abandonment  abc  abdomen  abide  \\\n",
       "2284   0.0      0.0        0.0         0.0          0.0  0.0      0.0    0.0   \n",
       "11948  0.0      0.0        0.0         0.0          0.0  0.0      0.0    0.0   \n",
       "9851   0.0      0.0        0.0         0.0          0.0  0.0      0.0    0.0   \n",
       "\n",
       "       ability  abit  ...  zach  zealand  zen  zero  zest  zombie  zone  zoom  \\\n",
       "2284       0.0   0.0  ...   0.0      0.0  0.0   0.0   0.0     0.0   0.0   0.0   \n",
       "11948      0.0   0.0  ...   0.0      0.0  0.0   0.0   0.0     0.0   0.0   0.0   \n",
       "9851       0.0   0.0  ...   0.0      0.0  0.0   0.0   0.0     0.0   0.0   0.0   \n",
       "\n",
       "       zooming  zumba  \n",
       "2284       0.0    0.0  \n",
       "11948      0.0    0.0  \n",
       "9851       0.0    0.0  \n",
       "\n",
       "[3 rows x 6495 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df = pd.DataFrame(tf_df.toarray(), columns=tfidf.get_feature_names_out())\n",
    "tf_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abc</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>abit</th>\n",
       "      <th>...</th>\n",
       "      <th>zach</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zen</th>\n",
       "      <th>zero</th>\n",
       "      <th>zest</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zumba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.006486</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>0.012614</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>0.006779</td>\n",
       "      <td>0.007231</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>0.016766</td>\n",
       "      <td>0.009148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>0.006198</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>0.007408</td>\n",
       "      <td>0.004508</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.009740</td>\n",
       "      <td>0.004746</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>0.004937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.521035</td>\n",
       "      <td>0.581781</td>\n",
       "      <td>0.818975</td>\n",
       "      <td>0.667780</td>\n",
       "      <td>0.586314</td>\n",
       "      <td>0.610155</td>\n",
       "      <td>0.729999</td>\n",
       "      <td>0.594738</td>\n",
       "      <td>0.541364</td>\n",
       "      <td>0.771920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676502</td>\n",
       "      <td>0.491465</td>\n",
       "      <td>0.430916</td>\n",
       "      <td>0.594343</td>\n",
       "      <td>0.488050</td>\n",
       "      <td>0.492643</td>\n",
       "      <td>0.513285</td>\n",
       "      <td>0.531097</td>\n",
       "      <td>0.552705</td>\n",
       "      <td>0.384099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 6495 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 aa       abandon     abandoned    abandoning   abandonment  \\\n",
       "count  15999.000000  15999.000000  15999.000000  15999.000000  15999.000000   \n",
       "mean       0.000088      0.000080      0.000250      0.000076      0.000092   \n",
       "std        0.006486      0.006044      0.012614      0.006844      0.006779   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        0.521035      0.581781      0.818975      0.667780      0.586314   \n",
       "\n",
       "                abc       abdomen         abide       ability          abit  \\\n",
       "count  15999.000000  15999.000000  15999.000000  15999.000000  15999.000000   \n",
       "mean       0.000111      0.000112      0.000084      0.000784      0.000138   \n",
       "std        0.007231      0.007563      0.006296      0.016766      0.009148   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        0.610155      0.729999      0.594738      0.541364      0.771920   \n",
       "\n",
       "       ...          zach       zealand           zen          zero  \\\n",
       "count  ...  15999.000000  15999.000000  15999.000000  15999.000000   \n",
       "mean   ...      0.000072      0.000096      0.000053      0.000137   \n",
       "std    ...      0.006537      0.006198      0.004726      0.007408   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...      0.676502      0.491465      0.430916      0.594343   \n",
       "\n",
       "               zest        zombie          zone          zoom       zooming  \\\n",
       "count  15999.000000  15999.000000  15999.000000  15999.000000  15999.000000   \n",
       "mean       0.000049      0.000127      0.000239      0.000051      0.000054   \n",
       "std        0.004508      0.007301      0.009740      0.004746      0.005011   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        0.488050      0.492643      0.513285      0.531097      0.552705   \n",
       "\n",
       "              zumba  \n",
       "count  15999.000000  \n",
       "mean       0.000067  \n",
       "std        0.004937  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        0.384099  \n",
       "\n",
       "[8 rows x 6495 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Either run this cell or the next, NOT both - this is for reproducible shuffling of train/test data\n",
    "random_seed = randint(0, 50)\n",
    "random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either run this cell or the above, NOT both\n",
    "random_seed = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12799, 6495), (12799,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    tf_df, edf['label'], test_size=0.2, random_state=random_seed, stratify=edf['label']\n",
    ")\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3200, 6495), (3200,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95375"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression().fit(X_train, y_train)\n",
    "lr_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.933125"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = MultinomialNB().fit(X_train, y_train)\n",
    "nb_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.940625"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier().fit(X_train, y_train)\n",
    "rf_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 20:27:26.128614: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 20:27:26.331778: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-05 20:27:26.331836: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-05 20:27:26.332588: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-05 20:27:26.414733: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "\n",
    "Adapted from [TensorFlow Text Classification RNN Tutorial](https://www.tensorflow.org/text/tutorials/text_classification_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_NUM = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=X_train.shape[1],\n",
    "        output_dim=DIM_NUM,\n",
    "        mask_zero=True), # Masking to handel variable sequence lengths? Is this even necessary?\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(DIM_NUM)),\n",
    "    tf.keras.layers.Dense(DIM_NUM, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Data adapters should be mutually exclusive for handling inputs. Found multiple adapters [<class 'keras.src.engine.data_adapter.TensorLikeDataAdapter'>, <class 'keras.src.engine.data_adapter.GeneratorDataAdapter'>] to handle input: <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.series.Series'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m single_layer_history \u001b[38;5;241m=\u001b[39m \u001b[43mrnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ece5831-py3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/ece5831-py3.10/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1111\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle input: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1107\u001b[0m             _type_name(x), _type_name(y)\n\u001b[1;32m   1108\u001b[0m         )\n\u001b[1;32m   1109\u001b[0m     )\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(adapter_cls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData adapters should be mutually exclusive for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandling inputs. Found multiple adapters \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[1;32m   1115\u001b[0m     )\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;66;03m# Instrument the data adapter usage before returning it\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m keras_data_adapter_gauge\u001b[38;5;241m.\u001b[39mget_cell(adapter_cls[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Data adapters should be mutually exclusive for handling inputs. Found multiple adapters [<class 'keras.src.engine.data_adapter.TensorLikeDataAdapter'>, <class 'keras.src.engine.data_adapter.GeneratorDataAdapter'>] to handle input: <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.series.Series'>"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "single_layer_history = rnn_model.fit(\n",
    "    X_train, y_train, validation_data=(X_test, y_test),\n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=callback\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece5831-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
