{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15999 entries, 0 to 15998\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   text     15999 non-null  object\n",
      " 1   emotion  15999 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 250.1+ KB\n"
     ]
    }
   ],
   "source": [
    "edf = pd.read_csv('data/emotions/train.txt', sep=';', header=0, names=['text', 'emotion'])\n",
    "edf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here if we want to use it. Leaving it off for now.\n",
    "def remove_contracted_terms(raw_text: str) -> str:\n",
    "    sep_patterns = [\n",
    "        r\"[\\s][^\\s]+n[\\s]+t[\\s]\",\n",
    "        r\"[\\s][Ii][\\s]+m[\\s]\",\n",
    "        r\"you[\\s]+re[\\s]\",\n",
    "        r\"they[\\s]+re[\\s]\",\n",
    "        r\"she[\\s]+s[\\s]\",\n",
    "        r\"[\\s]he[\\s]+s[\\s]\",\n",
    "        r\"[\\s][^\\s]+[\\s]+d[\\s]\",\n",
    "        r\"[\\s][^\\s]+[\\s]+ve[\\s]\"\n",
    "    ]\n",
    "    combo_pattern = re.compile('|'.join(sep_patterns))\n",
    "    return re.sub(combo_pattern, ' ', raw_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>contractions_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7680</th>\n",
       "      <td>i dont recall just now yet vividly recall look...</td>\n",
       "      <td>love</td>\n",
       "      <td>i dont recall just now yet vividly recall look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>i feel so embarrassed of myself for even havin...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i feel so embarrassed of myself for even havin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4466</th>\n",
       "      <td>i would feel so excited waiting for the mailma...</td>\n",
       "      <td>joy</td>\n",
       "      <td>i would feel so excited waiting for the mailma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14576</th>\n",
       "      <td>i growled at her i began to feel extremely ann...</td>\n",
       "      <td>anger</td>\n",
       "      <td>i growled at her i began to feel extremely ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>i am right now i feel amused the sounds i hear...</td>\n",
       "      <td>joy</td>\n",
       "      <td>i am right now i feel amused the sounds i hear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  emotion  \\\n",
       "7680   i dont recall just now yet vividly recall look...     love   \n",
       "5747   i feel so embarrassed of myself for even havin...  sadness   \n",
       "4466   i would feel so excited waiting for the mailma...      joy   \n",
       "14576  i growled at her i began to feel extremely ann...    anger   \n",
       "4460   i am right now i feel amused the sounds i hear...      joy   \n",
       "\n",
       "                                    contractions_removed  \n",
       "7680   i dont recall just now yet vividly recall look...  \n",
       "5747   i feel so embarrassed of myself for even havin...  \n",
       "4466   i would feel so excited waiting for the mailma...  \n",
       "14576  i growled at her i began to feel extremely ann...  \n",
       "4460   i am right now i feel amused the sounds i hear...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edf['contractions_removed'] = edf['text'].apply(remove_contracted_terms)\n",
    "edf.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>contractions_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>i feel that learning more about animals and th...</td>\n",
       "      <td>joy</td>\n",
       "      <td>i feel that learning more about animals and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9552</th>\n",
       "      <td>i am feeling a bit apprehensive about carrying...</td>\n",
       "      <td>fear</td>\n",
       "      <td>i am feeling a bit apprehensive about carrying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7054</th>\n",
       "      <td>im feeling very bitter against knight in shini...</td>\n",
       "      <td>anger</td>\n",
       "      <td>im feeling very bitter against knight in shini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>i don t always remember to do this but when i ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>i always remember to do this but when feeling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6786</th>\n",
       "      <td>i feel shes friendly and nice</td>\n",
       "      <td>joy</td>\n",
       "      <td>i feel shes friendly and nice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text emotion  \\\n",
       "4198   i feel that learning more about animals and th...     joy   \n",
       "9552   i am feeling a bit apprehensive about carrying...    fear   \n",
       "7054   im feeling very bitter against knight in shini...   anger   \n",
       "10405  i don t always remember to do this but when i ...   anger   \n",
       "6786                       i feel shes friendly and nice     joy   \n",
       "\n",
       "                                    contractions_removed  \n",
       "4198   i feel that learning more about animals and th...  \n",
       "9552   i am feeling a bit apprehensive about carrying...  \n",
       "7054   im feeling very bitter against knight in shini...  \n",
       "10405  i always remember to do this but when feeling ...  \n",
       "6786                       i feel shes friendly and nice  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edf.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15999 entries, 0 to 15998\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   text     15999 non-null  object\n",
      " 1   emotion  15999 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 250.1+ KB\n"
     ]
    }
   ],
   "source": [
    "edf.drop(columns=['contractions_removed'], inplace=True)\n",
    "edf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "joy         5362\n",
       "sadness     4665\n",
       "anger       2159\n",
       "fear        1937\n",
       "love        1304\n",
       "surprise     572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edf['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just going to roughly group \"sadness\", \"anger\", and \"fear\" into \"stressed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11727</th>\n",
       "      <td>i always feel rushed on the way to visit no co...</td>\n",
       "      <td>anger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12136</th>\n",
       "      <td>i have this kind of life so my girlfriend woul...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11560</th>\n",
       "      <td>i feel like ive been reading lisas blogs for e...</td>\n",
       "      <td>love</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  emotion  label\n",
       "11727  i always feel rushed on the way to visit no co...    anger      1\n",
       "12136  i have this kind of life so my girlfriend woul...  sadness      1\n",
       "11560  i feel like ive been reading lisas blogs for e...     love      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_stress = {'sadness', 'anger', 'fear'}\n",
    "edf['label'] = edf['emotion'].apply(lambda emotion: 1 if emotion.strip() in possible_stress else 0)\n",
    "edf.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "205\n"
     ]
    }
   ],
   "source": [
    "print(len(stop_words))\n",
    "utils.add_stopwords_missing_apostrophe(stop_words)\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>i should feel complimented or insulted</td>\n",
       "      <td>anger</td>\n",
       "      <td>1</td>\n",
       "      <td>feel complimented insulted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12418</th>\n",
       "      <td>i am inferior to them then i feel as i did as ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "      <td>inferior feel child respected listened allowed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5346</th>\n",
       "      <td>i would feel timid wearing them beacuse id try...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "      <td>would feel timid wearing beacuse id try get di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12091</th>\n",
       "      <td>i feel a little bit chukey and unfortunately f...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "      <td>feel little bit chukey unfortunately u like si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>i did successfully manage to stretch a mxm can...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "      <td>successfully manage stretch mxm canvas feel ac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text emotion  label  \\\n",
       "368               i should feel complimented or insulted   anger      1   \n",
       "12418  i am inferior to them then i feel as i did as ...     joy      0   \n",
       "5346   i would feel timid wearing them beacuse id try...    fear      1   \n",
       "12091  i feel a little bit chukey and unfortunately f...     joy      0   \n",
       "75     i did successfully manage to stretch a mxm can...     joy      0   \n",
       "\n",
       "                                          processed_text  \n",
       "368                           feel complimented insulted  \n",
       "12418  inferior feel child respected listened allowed...  \n",
       "5346   would feel timid wearing beacuse id try get di...  \n",
       "12091  feel little bit chukey unfortunately u like si...  \n",
       "75     successfully manage stretch mxm canvas feel ac...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edf['processed_text'] = edf['text'].apply(lambda raw_text: utils.process_text(\n",
    "    text_chunk=raw_text, stopwords=stop_words, lemmatizer_obj=lemmatizer\n",
    "))\n",
    "edf.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize (Word Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_freq_maxes = [0.9, 0.8, 0.7, 0.6, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max doc freq: 0.9\n",
      "Terms: 13435\n",
      "\n",
      "Max doc freq: 0.8\n",
      "Terms: 13435\n",
      "\n",
      "Max doc freq: 0.7\n",
      "Terms: 13435\n",
      "\n",
      "Max doc freq: 0.6\n",
      "Terms: 13434\n",
      "\n",
      "Max doc freq: 0.5\n",
      "Terms: 13434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ceiling in doc_freq_maxes:\n",
    "    tf = TfidfVectorizer(max_df=ceiling)\n",
    "    tf_df = tf.fit_transform(edf['processed_text'])\n",
    "    tf_df.toarray()\n",
    "    print(f'Max doc freq: {ceiling}\\nTerms: {tf_df.shape[1]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_freq_mins = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min doc freq: 0.1\n",
      "Terms: 4\n",
      "\n",
      "Min doc freq: 0.01\n",
      "Terms: 101\n",
      "\n",
      "Min doc freq: 0.001\n",
      "Terms: 1363\n",
      "\n",
      "Min doc freq: 0.0001\n",
      "Terms: 6496\n",
      "\n",
      "Min doc freq: 1e-05\n",
      "Terms: 13435\n",
      "\n",
      "Min doc freq: 0.0\n",
      "Terms: 13435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for floor in doc_freq_mins:\n",
    "    tf = TfidfVectorizer(min_df=floor)\n",
    "    tf_df = tf.fit_transform(edf['processed_text'])\n",
    "    tf_df.toarray()\n",
    "    print(f'Min doc freq: {floor}\\nTerms: {tf_df.shape[1]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try max_df = 0.6 and min_df = 0.0001\n",
    "MAX_DF = 0.6\n",
    "MIN_DF = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15999, 6495)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = TfidfVectorizer(min_df=MIN_DF, max_df=MAX_DF)\n",
    "tf_df = tf.fit_transform(edf['processed_text'])\n",
    "tf_df.toarray()\n",
    "tf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abc</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>abit</th>\n",
       "      <th>...</th>\n",
       "      <th>zach</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zen</th>\n",
       "      <th>zero</th>\n",
       "      <th>zest</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zumba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3685</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11226</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 6495 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        aa  abandon  abandoned  abandoning  abandonment  abc  abdomen  abide  \\\n",
       "3685   0.0      0.0        0.0         0.0          0.0  0.0      0.0    0.0   \n",
       "10294  0.0      0.0        0.0         0.0          0.0  0.0      0.0    0.0   \n",
       "11226  0.0      0.0        0.0         0.0          0.0  0.0      0.0    0.0   \n",
       "\n",
       "       ability  abit  ...  zach  zealand  zen  zero  zest  zombie  zone  zoom  \\\n",
       "3685       0.0   0.0  ...   0.0      0.0  0.0   0.0   0.0     0.0   0.0   0.0   \n",
       "10294      0.0   0.0  ...   0.0      0.0  0.0   0.0   0.0     0.0   0.0   0.0   \n",
       "11226      0.0   0.0  ...   0.0      0.0  0.0   0.0   0.0     0.0   0.0   0.0   \n",
       "\n",
       "       zooming  zumba  \n",
       "3685       0.0    0.0  \n",
       "10294      0.0    0.0  \n",
       "11226      0.0    0.0  \n",
       "\n",
       "[3 rows x 6495 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df = pd.DataFrame(tf_df.toarray(), columns=tf.get_feature_names_out())\n",
    "tf_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abc</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>abit</th>\n",
       "      <th>...</th>\n",
       "      <th>zach</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zen</th>\n",
       "      <th>zero</th>\n",
       "      <th>zest</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zumba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "      <td>15999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.006486</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>0.012614</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>0.006779</td>\n",
       "      <td>0.007231</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>0.016766</td>\n",
       "      <td>0.009148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>0.006198</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>0.007408</td>\n",
       "      <td>0.004508</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.009740</td>\n",
       "      <td>0.004746</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>0.004937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.521035</td>\n",
       "      <td>0.581781</td>\n",
       "      <td>0.818975</td>\n",
       "      <td>0.667780</td>\n",
       "      <td>0.586314</td>\n",
       "      <td>0.610155</td>\n",
       "      <td>0.729999</td>\n",
       "      <td>0.594738</td>\n",
       "      <td>0.541364</td>\n",
       "      <td>0.771920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676502</td>\n",
       "      <td>0.491465</td>\n",
       "      <td>0.430916</td>\n",
       "      <td>0.594343</td>\n",
       "      <td>0.488050</td>\n",
       "      <td>0.492643</td>\n",
       "      <td>0.513285</td>\n",
       "      <td>0.531097</td>\n",
       "      <td>0.552705</td>\n",
       "      <td>0.384099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 6495 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 aa       abandon     abandoned    abandoning   abandonment  \\\n",
       "count  15999.000000  15999.000000  15999.000000  15999.000000  15999.000000   \n",
       "mean       0.000088      0.000080      0.000250      0.000076      0.000092   \n",
       "std        0.006486      0.006044      0.012614      0.006844      0.006779   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        0.521035      0.581781      0.818975      0.667780      0.586314   \n",
       "\n",
       "                abc       abdomen         abide       ability          abit  \\\n",
       "count  15999.000000  15999.000000  15999.000000  15999.000000  15999.000000   \n",
       "mean       0.000111      0.000112      0.000084      0.000784      0.000138   \n",
       "std        0.007231      0.007563      0.006296      0.016766      0.009148   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        0.610155      0.729999      0.594738      0.541364      0.771920   \n",
       "\n",
       "       ...          zach       zealand           zen          zero  \\\n",
       "count  ...  15999.000000  15999.000000  15999.000000  15999.000000   \n",
       "mean   ...      0.000072      0.000096      0.000053      0.000137   \n",
       "std    ...      0.006537      0.006198      0.004726      0.007408   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...      0.676502      0.491465      0.430916      0.594343   \n",
       "\n",
       "               zest        zombie          zone          zoom       zooming  \\\n",
       "count  15999.000000  15999.000000  15999.000000  15999.000000  15999.000000   \n",
       "mean       0.000049      0.000127      0.000239      0.000051      0.000054   \n",
       "std        0.004508      0.007301      0.009740      0.004746      0.005011   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        0.488050      0.492643      0.513285      0.531097      0.552705   \n",
       "\n",
       "              zumba  \n",
       "count  15999.000000  \n",
       "mean       0.000067  \n",
       "std        0.004937  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        0.384099  \n",
       "\n",
       "[8 rows x 6495 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Either run this cell or the next, NOT both\n",
    "random_seed = randint(0, 50)\n",
    "random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either run this cell or the above, NOT both\n",
    "random_seed = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12799, 6495), (12799,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    tf_df, edf['label'], test_size=0.2, random_state=random_seed, stratify=edf['label']\n",
    ")\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3200, 6495), (3200,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95375"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression().fit(X_train, y_train)\n",
    "lr_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.933125"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = MultinomialNB().fit(X_train, y_train)\n",
    "nb_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.940625"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier().fit(X_train, y_train)\n",
    "rf_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece5831-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
